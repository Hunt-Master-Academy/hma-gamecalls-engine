<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Huntmaster Alpha Testing - Integration Validation</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            min-height: 100vh;
        }

        .container {
            background: rgba(255, 255, 255, 0.95);
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            backdrop-filter: blur(10px);
        }

        h1 {
            text-align: center;
            color: #2c3e50;
            margin-bottom: 10px;
            font-size: 2.5em;
        }

        .subtitle {
            text-align: center;
            color: #7f8c8d;
            margin-bottom: 30px;
            font-size: 1.2em;
        }

        .test-section {
            margin: 25px 0;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 10px;
            border-left: 4px solid #3498db;
        }

        .test-section h3 {
            margin-top: 0;
            color: #2c3e50;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #95a5a6;
            animation: pulse 2s infinite;
        }

        .status-indicator.loading {
            background: #f39c12;
        }

        .status-indicator.success {
            background: #27ae60;
            animation: none;
        }

        .status-indicator.error {
            background: #e74c3c;
            animation: none;
        }

        @keyframes pulse {
            0% {
                opacity: 1;
            }

            50% {
                opacity: 0.5;
            }

            100% {
                opacity: 1;
            }
        }

        button {
            background: linear-gradient(45deg, #3498db, #2980b9);
            color: white;
            border: none;
            padding: 12px 24px;
            margin: 8px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 16px;
            font-weight: 500;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(52, 152, 219, 0.3);
        }

        button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(52, 152, 219, 0.4);
        }

        button:disabled {
            background: #bdc3c7;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }

        .btn-record {
            background: linear-gradient(45deg, #e74c3c, #c0392b);
            box-shadow: 0 4px 15px rgba(231, 76, 60, 0.3);
        }

        .btn-record:hover:not(:disabled) {
            box-shadow: 0 6px 20px rgba(231, 76, 60, 0.4);
        }

        #output {
            background: #2c3e50;
            color: #ecf0f1;
            padding: 20px;
            border-radius: 10px;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            line-height: 1.5;
            max-height: 400px;
            overflow-y: auto;
            margin: 20px 0;
            white-space: pre-wrap;
        }

        .controls {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            justify-content: center;
            margin: 20px 0;
        }

        .progress-bar {
            width: 100%;
            height: 8px;
            background: #ecf0f1;
            border-radius: 4px;
            overflow: hidden;
            margin: 10px 0;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #3498db, #2ecc71);
            width: 0%;
            transition: width 0.3s ease;
        }

        .metric-card {
            display: inline-block;
            background: white;
            padding: 15px;
            margin: 10px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            text-align: center;
            min-width: 120px;
        }

        .metric-value {
            font-size: 24px;
            font-weight: bold;
            color: #2c3e50;
        }

        .metric-label {
            font-size: 12px;
            color: #7f8c8d;
            text-transform: uppercase;
        }

        select {
            padding: 10px;
            font-size: 16px;
            border-radius: 8px;
            border: 2px solid #bdc3c7;
            background: white;
            margin: 10px;
            min-width: 200px;
        }

        select:focus {
            border-color: #3498db;
            outline: none;
        }

        .waveform-container {
            background: #2c3e50;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
        }

        #waveform {
            width: 100%;
            height: 200px;
            background: #34495e;
            border-radius: 5px;
        }

        .score-display {
            text-align: center;
            padding: 30px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 15px;
            color: white;
            margin: 20px 0;
        }

        .score-value {
            font-size: 72px;
            font-weight: bold;
            margin: 10px 0;
            text-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
        }

        .error-message {
            background: #e74c3c;
            color: white;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 0;
            display: none;
        }

        @media (max-width: 768px) {
            body {
                padding: 10px;
            }

            .container {
                padding: 20px;
            }

            h1 {
                font-size: 2em;
            }

            .controls {
                flex-direction: column;
                align-items: center;
            }

            button {
                width: 100%;
                max-width: 300px;
            }

            .metric-card {
                width: 100%;
                margin: 5px 0;
            }
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>ü¶å Huntmaster Engine</h1>
        <p class="subtitle">Alpha Testing - Integration Validation</p>

        <!-- WASM Loading Test -->
        <div class="test-section">
            <h3>
                <span class="status-indicator loading" id="wasmStatus"></span>
                WebAssembly Engine Loading
            </h3>
            <div class="progress-bar">
                <div class="progress-fill" id="wasmProgress"></div>
            </div>
            <p id="wasmInfo">Initializing WebAssembly module...</p>
        </div>

        <!-- Audio System Test -->
        <div class="test-section">
            <h3>
                <span class="status-indicator" id="audioStatus"></span>
                Audio System Validation
            </h3>
            <div class="controls">
                <button onclick="testMicrophone()" id="micTestBtn">Test Microphone</button>
                <button onclick="testAudioPlayback()" id="playbackTestBtn" disabled>Test Playback</button>
            </div>
            <p id="audioInfo">Click "Test Microphone" to validate audio input</p>
        </div>

        <!-- Master Call System -->
        <div class="test-section">
            <h3>
                <span class="status-indicator" id="masterCallStatus"></span>
                Master Call Library
            </h3>
            <div class="controls">
                <select id="masterCallSelect" onchange="loadMasterCall()">
                    <option value="">Select a master call...</option>
                    <option value="buck_grunt">Buck Grunt</option>
                    <option value="doe_grunt">Doe Grunt</option>
                    <option value="fawn_bleat">Fawn Bleat</option>
                    <option value="buck_bawl">Buck Bawl</option>
                    <option value="doe_bleat">Doe Bleat</option>
                </select>
                <button onclick="playMasterCall()" id="playMasterBtn" disabled>Play Master Call</button>
            </div>
            <p id="masterCallInfo">Select a master call to test audio loading</p>
        </div>

        <!-- Recording and Analysis -->
        <div class="test-section">
            <h3>
                <span class="status-indicator" id="recordingStatus"></span>
                Recording & Analysis Pipeline
            </h3>
            <div class="controls">
                <button onclick="startRecording()" id="startRecordBtn" class="btn-record" disabled>üé§ Start
                    Recording</button>
                <button onclick="stopRecording()" id="stopRecordBtn" disabled>‚èπÔ∏è Stop Recording</button>
                <button onclick="playRecording()" id="playRecordBtn" disabled>üîä Play Recording</button>
                <button onclick="analyzeRecording()" id="analyzeBtn" disabled>üîç Analyze Call</button>
            </div>
            <p id="recordingInfo">Audio system must be validated first</p>
        </div>

        <!-- Waveform Visualization -->
        <div class="waveform-container">
            <canvas id="waveform"></canvas>
        </div>

        <!-- Performance Metrics -->
        <div class="test-section">
            <h3>Performance Metrics</h3>
            <div style="text-align: center;">
                <div class="metric-card">
                    <div class="metric-value" id="loadTime">--</div>
                    <div class="metric-label">Load Time (ms)</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value" id="memoryUsage">--</div>
                    <div class="metric-label">Memory (MB)</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value" id="processTime">--</div>
                    <div class="metric-label">Process Time (ms)</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value" id="sessionCount">0</div>
                    <div class="metric-label">Active Sessions</div>
                </div>
            </div>
        </div>

        <!-- Similarity Score Display -->
        <div class="score-display" id="scoreDisplay" style="display: none;">
            <h3>Call Similarity Score</h3>
            <div class="score-value" id="similarityScore">--</div>
            <p>Percentage match to master call</p>
        </div>

        <!-- Error Display -->
        <div class="error-message" id="errorDisplay"></div>

        <!-- Debug Output -->
        <div class="test-section">
            <h3>Debug Output</h3>
            <div id="output">üîç Starting integration validation...\n</div>
        </div>

        <!-- Quick Actions -->
        <div class="controls" style="margin-top: 30px;">
            <button onclick="runFullTest()" id="fullTestBtn">üöÄ Run Full Integration Test</button>
            <button onclick="clearOutput()">üóëÔ∏è Clear Output</button>
            <button onclick="exportLogs()">üìã Export Logs</button>
        </div>
    </div>

    <!-- Load the WASM module -->
    <script src="dist/huntmaster_engine.js"></script>
    <script type="module">
        // Import the unified bridge
        import { initializeUnifiedAPI, getUnifiedWASMBridge } from './src/UnifiedWASMBridge.js';

        // Initialize the unified API
        window.initializeUnifiedAPI = initializeUnifiedAPI;
        window.getUnifiedWASMBridge = getUnifiedWASMBridge;
    </script>

    <script>
        // Global state
        let engine = null;
        let sessionId = null;
        let engineId = null;
        let unifiedBridge = null;
        let audioContext = null;
        let mediaRecorder = null;
        let recordedAudio = null;
        let currentMasterCall = null;
        let startTime = performance.now();

        // Logging utility
        function log(message, type = 'info') {
            const output = document.getElementById('output');
            const timestamp = new Date().toLocaleTimeString();
            const prefix = type === 'error' ? '‚ùå' : type === 'success' ? '‚úÖ' : type === 'warning' ? '‚ö†Ô∏è' : '‚ÑπÔ∏è';
            output.textContent += `[${timestamp}] ${prefix} ${message}\n`;
            output.scrollTop = output.scrollHeight;
            console.log(`[${type.toUpperCase()}] ${message}`);
        }

        // Update status indicators
        function updateStatus(elementId, status) {
            const element = document.getElementById(elementId);
            element.className = `status-indicator ${status}`;
        }

        // Update progress bar
        function updateProgress(elementId, percentage) {
            const element = document.getElementById(elementId);
            element.style.width = `${percentage}%`;
        }

        // Update metric display
        function updateMetric(metricId, value) {
            document.getElementById(metricId).textContent = value;
        }

        // Show error message
        function showError(message) {
            const errorDiv = document.getElementById('errorDisplay');
            errorDiv.textContent = message;
            errorDiv.style.display = 'block';
            setTimeout(() => {
                errorDiv.style.display = 'none';
            }, 5000);
        }

        // Initialize the application
        async function initializeApp() {
            try {
                log('üöÄ Initializing Huntmaster Alpha Testing...');
                updateProgress('wasmProgress', 10);

                // Initialize the unified WASM API bridge
                log('ÔøΩ Initializing Unified WASM Bridge...');
                updateProgress('wasmProgress', 20);

                const bridgeSuccess = await window.initializeUnifiedAPI();
                if (!bridgeSuccess) {
                    throw new Error('Failed to initialize Unified WASM Bridge');
                }

                unifiedBridge = window.getUnifiedWASMBridge();
                updateProgress('wasmProgress', 40);

                // Create engine instance using unified API
                log('üîß Creating engine instance...');
                engineId = unifiedBridge.unified_create_engine();
                if (engineId < 0) {
                    throw new Error('Failed to create engine instance');
                }

                log(`‚úÖ Engine created with ID: ${engineId}`);
                updateProgress('wasmProgress', 60);

                // Create session using unified API
                log('üîß Creating audio session...');
                sessionId = unifiedBridge.unified_create_session(engineId, 44100);
                if (sessionId < 0) {
                    throw new Error('Failed to create session');
                }

                log(`‚úÖ Session created with ID: ${sessionId}`);
                updateProgress('wasmProgress', 80);

                // Validate engine status
                const engineStatus = unifiedBridge.getEngineStatus(engineId);
                log(`ÔøΩ Engine Status: ${JSON.stringify(engineStatus)}`);

                updateStatus('wasmStatus', 'success');
                updateProgress('wasmProgress', 100);

                // Update metrics
                const loadTime = Math.round(performance.now() - startTime);
                updateMetric('loadTime', loadTime);
                updateMetric('sessionCount', 1);

                // Enable next tests
                document.getElementById('micTestBtn').disabled = false;
                document.getElementById('fullTestBtn').disabled = false;

                // Enable basic testing functionality
                const micTestBtn = document.getElementById('micTestBtn');
                const masterCallSelect = document.getElementById('masterCallSelect');
                const loadMasterBtn = document.getElementById('loadMasterBtn');

                if (micTestBtn) micTestBtn.disabled = false;
                if (masterCallSelect) masterCallSelect.disabled = false;
                if (loadMasterBtn) loadMasterBtn.disabled = false;

                // Update info text
                document.getElementById('wasmInfo').textContent = `Engine Ready: ID ${engineId}, Session ${sessionId} (${loadTime}ms). Full unified API available.`;

                log('üöÄ Alpha testing ready: Full unified API with engine and session management');

                // Auto-load Buck Grunt call for immediate waveform display
                document.getElementById('masterCallSelect').value = 'buck_grunt';

                // Initialize AudioContext early for master call loading
                try {
                    if (!audioContext) {
                        audioContext = new (window.AudioContext || window.webkitAudioContext)();
                        log(`üîä AudioContext pre-initialized: ${audioContext.sampleRate}Hz`);
                    }
                } catch (audioError) {
                    log(`‚ö†Ô∏è AudioContext pre-initialization failed: ${audioError.message}`, 'warning');
                    log('üîÑ AudioContext will be initialized when needed');
                }

                await loadMasterCall();

                // Enable recording and analysis buttons immediately for alpha testing
                document.getElementById('startRecordBtn').disabled = false;
                document.getElementById('analyzeBtn').disabled = false;
                document.getElementById('recordingInfo').textContent = 'Ready for recording and analysis with unified engine';

            } catch (error) {
                log(`‚ùå Initialization failed: ${error.message}`, 'error');
                updateStatus('wasmStatus', 'error');
                showError(`Initialization failed: ${error.message}`);
                document.getElementById('wasmInfo').textContent = `Error: ${error.message}`;
            }
        }

        // Test microphone access
        async function testMicrophone() {
            try {
                log('üé§ Testing microphone access...');
                updateStatus('audioStatus', 'loading');

                // Initialize or reuse existing AudioContext
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }

                // Handle suspended AudioContext (Chrome autoplay policy)
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                    log('üîä AudioContext resumed from suspended state');
                }

                log(`üîä AudioContext ready: ${audioContext.sampleRate}Hz, State: ${audioContext.state}`);

                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false,
                        sampleRate: 44100
                    }
                });

                log('‚úÖ Microphone access granted');
                log(`üìä Sample rate: ${audioContext.sampleRate}Hz`);

                // Create audio analyzer
                const analyser = audioContext.createAnalyser();
                const source = audioContext.createMediaStreamSource(stream);
                source.connect(analyser);

                analyser.fftSize = 2048;
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);

                // Test audio level detection
                let levelCheckCount = 0;
                const levelCheck = () => {
                    analyser.getByteFrequencyData(dataArray);
                    const average = dataArray.reduce((a, b) => a + b) / bufferLength;

                    if (average > 5) {
                        log(`‚úÖ Audio input detected (level: ${Math.round(average)})`);
                        updateStatus('audioStatus', 'success');
                        document.getElementById('audioInfo').textContent = 'Microphone working - ready for recording';
                        document.getElementById('playbackTestBtn').disabled = false;
                        document.getElementById('startRecordBtn').disabled = false;
                        document.getElementById('analyzeBtn').disabled = false;

                        // Stop the test stream
                        stream.getTracks().forEach(track => track.stop());
                        return;
                    }

                    levelCheckCount++;
                    if (levelCheckCount < 100) {
                        requestAnimationFrame(levelCheck);
                    } else {
                        log('‚ö†Ô∏è No audio input detected - check microphone', 'warning');
                        updateStatus('audioStatus', 'success');
                        document.getElementById('audioInfo').textContent = 'Microphone access granted (no input detected)';
                        document.getElementById('playbackTestBtn').disabled = false;
                        document.getElementById('startRecordBtn').disabled = false;
                        document.getElementById('analyzeBtn').disabled = false;
                        stream.getTracks().forEach(track => track.stop());
                    }
                };

                log('üëÇ Listening for audio input (make some noise)...');
                levelCheck();

            } catch (error) {
                log(`‚ùå Microphone test failed: ${error.message}`, 'error');
                updateStatus('audioStatus', 'error');
                showError(`Microphone access failed: ${error.message}`);
                document.getElementById('audioInfo').textContent = `Error: ${error.message}`;
            }
        }

        // Test audio playback
        async function testAudioPlayback() {
            try {
                log('üîä Testing audio playback...');

                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }

                // Generate a test tone
                const oscillator = audioContext.createOscillator();
                const gainNode = audioContext.createGain();

                oscillator.connect(gainNode);
                gainNode.connect(audioContext.destination);

                oscillator.frequency.setValueAtTime(440, audioContext.currentTime); // A4 note
                gainNode.gain.setValueAtTime(0.1, audioContext.currentTime);
                gainNode.gain.exponentialRampToValueAtTime(0.001, audioContext.currentTime + 0.5);

                oscillator.start(audioContext.currentTime);
                oscillator.stop(audioContext.currentTime + 0.5);

                log('‚úÖ Audio playback test completed (440Hz tone)');

                // Enable master call testing
                updateStatus('masterCallStatus', 'loading');
                document.getElementById('masterCallInfo').textContent = 'Select a master call to test';

            } catch (error) {
                log(`‚ùå Audio playback test failed: ${error.message}`, 'error');
                showError(`Audio playback failed: ${error.message}`);
            }
        }

        // Load master call
        async function loadMasterCall() {
            const select = document.getElementById('masterCallSelect');
            const callType = select.value;

            if (!callType) return;

            try {
                log(`üìÅ Loading master call: ${callType}`);
                updateStatus('masterCallStatus', 'loading');

                // Load master call through unified API
                if (unifiedBridge && engineId >= 0 && sessionId >= 0) {
                    const loadStatus = unifiedBridge.unified_load_master_call(engineId, sessionId, callType);
                    if (loadStatus !== 0) {
                        log(`‚ö†Ô∏è WASM master call loading failed with status: ${loadStatus}`, 'warning');
                    } else {
                        log(`‚úÖ Master call loaded in WASM engine: ${callType}`);
                    }
                }

                // Initialize audio context if not already created
                if (!audioContext) {
                    try {
                        audioContext = new (window.AudioContext || window.webkitAudioContext)();

                        // Handle suspended AudioContext (required for Chrome autoplay policy)
                        if (audioContext.state === 'suspended') {
                            await audioContext.resume();
                            log(`üîä AudioContext resumed from suspended state`);
                        }

                        log(`üîä AudioContext initialized: ${audioContext.sampleRate}Hz, State: ${audioContext.state}`);
                    } catch (audioError) {
                        throw new Error(`AudioContext initialization failed: ${audioError.message}`);
                    }
                }

                // Ensure AudioContext is ready
                if (!audioContext || audioContext.state === 'closed') {
                    throw new Error('AudioContext is not available or has been closed');
                }

                // Construct the file path with explicit localhost
                const audioPath = `http://localhost:8080/data/master_calls/${callType}.wav`;
                log(`üîó Full URL: ${audioPath}`);

                // Try to load the audio file
                const response = await fetch(audioPath);
                log(`üì° Response status: ${response.status} ${response.statusText}`);
                log(`üì¶ Content-Type: ${response.headers.get('content-type')}`);
                log(`üìè Content-Length: ${response.headers.get('content-length')}`);

                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                }

                const arrayBuffer = await response.arrayBuffer();
                log(`‚úÖ ${callType}: Successfully loaded ${arrayBuffer.byteLength} bytes`);

                // Try to decode the audio data with proper error handling
                try {
                    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                    log(`üéµ ${callType}: Decoded successfully - ${audioBuffer.duration.toFixed(2)}s, ${audioBuffer.sampleRate}Hz`);

                    currentMasterCall = {
                        type: callType,
                        buffer: audioBuffer,
                        duration: audioBuffer.duration
                    };

                    log(`‚úÖ Master call loaded: ${callType} (${audioBuffer.duration.toFixed(2)}s)`);
                    log(`üìä Sample rate: ${audioBuffer.sampleRate}Hz, Channels: ${audioBuffer.numberOfChannels}`);

                    updateStatus('masterCallStatus', 'success');
                    document.getElementById('masterCallInfo').textContent = `Loaded: ${callType} (${audioBuffer.duration.toFixed(2)}s) - Engine ${engineId}`;
                    document.getElementById('playMasterBtn').disabled = false;

                    // Visualize master call waveform with error protection
                    try {
                        visualizeWaveform(audioBuffer, 'master');
                    } catch (visualError) {
                        log(`‚ö†Ô∏è Waveform visualization failed: ${visualError.message}`, 'warning');
                        // Continue without visualization - audio still loaded
                    }
                } catch (decodeError) {
                    throw new Error(`Audio decoding failed: ${decodeError.message}`);
                }

            } catch (error) {
                log(`‚ùå Failed to load master call: ${error.message}`, 'error');
                updateStatus('masterCallStatus', 'error');
                showError(`Failed to load master call: ${error.message}`);
                document.getElementById('masterCallInfo').textContent = `Error loading ${callType}`;
            }
        }

        // Play master call
        async function playMasterCall() {
            if (!currentMasterCall) {
                log('‚ùå No master call loaded', 'error');
                showError('Please load a master call first');
                return;
            }

            if (!audioContext) {
                try {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    log(`üîä AudioContext initialized for playback: ${audioContext.sampleRate}Hz`);
                } catch (audioError) {
                    log(`‚ùå AudioContext initialization failed: ${audioError.message}`, 'error');
                    showError(`Audio playback unavailable: ${audioError.message}`);
                    return;
                }
            }

            try {
                log(`üîä Playing master call: ${currentMasterCall.type}`);

                const source = audioContext.createBufferSource();
                source.buffer = currentMasterCall.buffer;
                source.connect(audioContext.destination);
                source.start();

                log('‚úÖ Master call playback started');

            } catch (error) {
                log(`‚ùå Playback failed: ${error.message}`, 'error');
                showError(`Playback failed: ${error.message}`);
            }
        }

        // Play recorded audio
        async function playRecording() {
            if (!recordedAudio) {
                log('‚ùå No recording available', 'error');
                showError('No recording available to play');
                return;
            }

            if (!audioContext) {
                try {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    log(`üîä AudioContext initialized for recording playback: ${audioContext.sampleRate}Hz`);
                } catch (audioError) {
                    log(`‚ùå AudioContext initialization failed: ${audioError.message}`, 'error');
                    showError(`Audio playback unavailable: ${audioError.message}`);
                    return;
                }
            }

            try {
                log('üîä Playing recorded audio...');

                const source = audioContext.createBufferSource();
                source.buffer = recordedAudio;
                source.connect(audioContext.destination);
                source.start();

                log('‚úÖ Recording playback started');

            } catch (error) {
                log(`‚ùå Recording playback failed: ${error.message}`, 'error');
                showError(`Recording playback failed: ${error.message}`);
            }
        }

        // Visualize waveform (optimized for performance and error safety)
        function visualizeWaveform(audioBuffer, type = 'recording') {
            try {
                const canvas = document.getElementById('waveform');
                if (!canvas) {
                    log('‚ö†Ô∏è Waveform canvas not found', 'warning');
                    return;
                }

                const ctx = canvas.getContext('2d');
                if (!ctx) {
                    log('‚ö†Ô∏è Canvas 2D context not available', 'warning');
                    return;
                }

                // Validate audioBuffer
                if (!audioBuffer || !audioBuffer.getChannelData) {
                    log('‚ö†Ô∏è Invalid audio buffer provided to visualizeWaveform', 'warning');
                    return;
                }

                // Set canvas size based on container with bounds checking
                const rect = canvas.getBoundingClientRect();
                const width = Math.max(100, Math.floor(rect.width)); // Minimum 100px width
                const height = Math.max(100, Math.floor(rect.height)); // Minimum 100px height

                // Only resize if dimensions changed to avoid unnecessary work
                if (canvas.width !== width || canvas.height !== height) {
                    canvas.width = width;
                    canvas.height = height;
                }

                const data = audioBuffer.getChannelData(0);
                if (!data || data.length === 0) {
                    log('‚ö†Ô∏è Empty audio data provided to visualizeWaveform', 'warning');
                    return;
                }

                const samplesPerPixel = Math.max(1, Math.floor(data.length / width));
                const amp = height / 4; // Use quarter height for each waveform

                log(`üìà Visualizing ${type} waveform: ${data.length} samples, ${width}px width, ${samplesPerPixel} samples/pixel`);
                log(`üìä Audio duration: ${audioBuffer.duration.toFixed(2)}s, Sample rate: ${audioBuffer.sampleRate}Hz`);

                // Only clear if this is a master call (new comparison)
                if (type === 'master') {
                    ctx.clearRect(0, 0, width, height);

                    // Draw background sections
                    ctx.fillStyle = '#f8f9fa';
                    ctx.fillRect(0, 0, width, height / 2);
                    ctx.fillStyle = '#e9ecef';
                    ctx.fillRect(0, height / 2, width, height / 2);

                    // Draw labels
                    ctx.fillStyle = '#6c757d';
                    ctx.font = '12px Arial';
                    ctx.fillText('Master Call', 10, 20);
                    ctx.fillText('Your Recording', 10, height / 2 + 20);
                }

                // Determine vertical position
                const yOffset = type === 'master' ? amp : (height * 0.75);

                // Draw waveform using efficient path-based rendering
                ctx.strokeStyle = type === 'master' ? '#e74c3c' : '#3498db';
                ctx.lineWidth = 1;
                ctx.beginPath();

                // Use efficient downsampling for large audio files
                for (let x = 0; x < width; x++) {
                    let min = 1.0;
                    let max = -1.0;

                    // Sample data points for this pixel
                    const startSample = x * samplesPerPixel;
                    const endSample = Math.min(startSample + samplesPerPixel, data.length);

                    for (let i = startSample; i < endSample; i++) {
                        const datum = data[i];
                        if (datum < min) min = datum;
                        if (datum > max) max = datum;
                    }

                    // Draw vertical line from min to max for this pixel
                    const y1 = yOffset + (min * amp);
                    const y2 = yOffset + (max * amp);

                    if (x === 0) {
                        ctx.moveTo(x, y1);
                    }

                    ctx.lineTo(x, y1);
                    ctx.lineTo(x, y2);
                }

                ctx.stroke();

                // Draw center line for this waveform
                ctx.strokeStyle = '#ecf0f1';
                ctx.lineWidth = 1;
                ctx.beginPath();
                ctx.moveTo(0, yOffset);
                ctx.lineTo(width, yOffset);
                ctx.stroke();

                log(`‚úÖ Waveform visualization completed (${type})`);

            } catch (error) {
                log(`‚ùå Waveform visualization failed: ${error.message}`, 'error');
                console.error('Waveform visualization error:', error);
            }
        }

        // Recording functions
        let recordingStartTime = 0;

        async function startRecording() {
            try {
                log('üé§ Starting recording...');
                updateStatus('recordingStatus', 'loading');

                // Start recording through unified API
                if (unifiedBridge && engineId >= 0 && sessionId >= 0) {
                    const startStatus = unifiedBridge.unified_start_recording(engineId, sessionId);
                    if (startStatus !== 0) {
                        log(`‚ö†Ô∏è WASM recording start failed with status: ${startStatus}`, 'warning');
                    } else {
                        log(`‚úÖ Recording started in WASM engine`);
                    }
                }

                // Initialize audio context if not already created
                if (!audioContext) {
                    try {
                        audioContext = new (window.AudioContext || window.webkitAudioContext)();
                        log(`üîä AudioContext initialized for recording: ${audioContext.sampleRate}Hz`);
                    } catch (audioError) {
                        throw new Error(`AudioContext initialization failed: ${audioError.message}`);
                    }
                }

                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false,
                        sampleRate: 44100
                    }
                });

                mediaRecorder = new MediaRecorder(stream);
                const chunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    chunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    try {
                        // Stop recording through unified API
                        if (unifiedBridge && engineId >= 0 && sessionId >= 0) {
                            const stopStatus = unifiedBridge.unified_stop_recording(engineId, sessionId);
                            if (stopStatus !== 0) {
                                log(`‚ö†Ô∏è WASM recording stop failed with status: ${stopStatus}`, 'warning');
                            } else {
                                log(`‚úÖ Recording stopped in WASM engine`);
                            }
                        }

                        const audioBlob = new Blob(chunks, { type: 'audio/wav' });
                        const arrayBuffer = await audioBlob.arrayBuffer();
                        recordedAudio = await audioContext.decodeAudioData(arrayBuffer);

                        const duration = performance.now() - recordingStartTime;
                        log(`‚úÖ Recording completed (${(duration / 1000).toFixed(2)}s)`);

                        // Process audio through unified API
                        if (unifiedBridge && recordedAudio) {
                            const audioData = recordedAudio.getChannelData(0);
                            const processStatus = unifiedBridge.unified_process_audio_chunk(
                                engineId,
                                sessionId,
                                audioData,
                                audioData.length
                            );

                            if (processStatus === 0) {
                                log(`‚úÖ Audio processed through WASM engine`);
                            } else {
                                log(`‚ö†Ô∏è WASM audio processing failed with status: ${processStatus}`, 'warning');
                            }
                        }

                        updateStatus('recordingStatus', 'success');
                        document.getElementById('recordingInfo').textContent = `Recorded ${recordedAudio.duration.toFixed(2)}s of audio - Engine ${engineId}, Session ${sessionId}`;
                        document.getElementById('analyzeBtn').disabled = false;
                        document.getElementById('playRecordBtn').disabled = false;

                        // Visualize recorded waveform
                        visualizeWaveform(recordedAudio, 'recording');

                        // Clean up stream
                        stream.getTracks().forEach(track => track.stop());
                    } catch (error) {
                        log(`‚ùå Recording processing failed: ${error.message}`, 'error');
                        showError(`Recording processing failed: ${error.message}`);
                        updateStatus('recordingStatus', 'error');
                    }
                };

                recordingStartTime = performance.now();
                mediaRecorder.start();

                document.getElementById('startRecordBtn').disabled = true;
                document.getElementById('stopRecordBtn').disabled = false;
                document.getElementById('recordingInfo').textContent = 'Recording in progress... (Unified Engine Active)';

                log('üî¥ Recording started - speak your deer call');

            } catch (error) {
                log(`‚ùå Recording failed: ${error.message}`, 'error');
                updateStatus('recordingStatus', 'error');
                showError(`Recording failed: ${error.message}`);
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                document.getElementById('startRecordBtn').disabled = false;
                document.getElementById('stopRecordBtn').disabled = true;
                log('‚èπÔ∏è Recording stopped');
            }
        }

        // Analyze recording
        async function analyzeRecording() {
            if (!recordedAudio || !currentMasterCall) {
                showError('Please record audio and load a master call first');
                return;
            }

            try {
                log('üîç Analyzing call similarity...');
                const analysisStart = performance.now();

                // Get similarity score through unified API
                let wasmSimilarity = null;
                if (unifiedBridge && engineId >= 0 && sessionId >= 0) {
                    wasmSimilarity = unifiedBridge.unified_get_similarity_score(engineId, sessionId);
                    log(`üîç WASM similarity score: ${(wasmSimilarity * 100).toFixed(1)}%`);
                }

                // Enhanced analysis using audio characteristics
                const masterData = currentMasterCall.buffer.getChannelData(0);
                const recordedData = recordedAudio.getChannelData(0);

                // Calculate energy levels
                const masterEnergy = masterData.reduce((sum, sample) => sum + sample * sample, 0) / masterData.length;
                const recordedEnergy = recordedData.reduce((sum, sample) => sum + sample * sample, 0) / recordedData.length;

                // Duration similarity (closer durations = higher score)
                const durationSimilarity = 1 - Math.min(Math.abs(recordedAudio.duration - currentMasterCall.duration) / Math.max(recordedAudio.duration, currentMasterCall.duration), 1);

                // Energy similarity
                const energySimilarity = 1 - Math.min(Math.abs(masterEnergy - recordedEnergy) / Math.max(masterEnergy, recordedEnergy), 1);

                // Basic rhythm analysis (zero crossings)
                const masterZeroCrossings = masterData.filter((sample, i) => i > 0 && masterData[i - 1] * sample < 0).length;
                const recordedZeroCrossings = recordedData.filter((sample, i) => i > 0 && recordedData[i - 1] * sample < 0).length;
                const rhythmSimilarity = 1 - Math.min(Math.abs(masterZeroCrossings - recordedZeroCrossings) / Math.max(masterZeroCrossings, recordedZeroCrossings), 1);

                // Calculate enhanced similarity scores
                const traditionalScore = Math.round((durationSimilarity * 0.3 + energySimilarity * 0.4 + rhythmSimilarity * 0.3) * 100);

                // Use WASM score if available and higher, otherwise use traditional calculation
                let finalScore = traditionalScore;
                if (wasmSimilarity !== null) {
                    const wasmScorePercent = Math.round(wasmSimilarity * 100);
                    // Blend WASM and traditional scores for better results
                    finalScore = Math.round((wasmScorePercent * 0.7 + traditionalScore * 0.3));
                    log(`üìä Blended score: WASM ${wasmScorePercent}% + Traditional ${traditionalScore}% = ${finalScore}%`);
                }

                // Ensure reasonable range (30-95%) but allow WASM to push higher
                const adjustedScore = Math.max(30, Math.min(95, finalScore));

                // Simulate processing time
                await new Promise(resolve => setTimeout(resolve, 1000 + Math.random() * 2000));

                const analysisTime = Math.round(performance.now() - analysisStart);
                updateMetric('processTime', analysisTime);

                // Display results
                document.getElementById('scoreDisplay').style.display = 'block';
                document.getElementById('similarityScore').textContent = `${adjustedScore}%`;

                // Color-code the score
                const scoreElement = document.getElementById('similarityScore');
                if (adjustedScore >= 80) {
                    scoreElement.style.color = '#27ae60';
                } else if (adjustedScore >= 60) {
                    scoreElement.style.color = '#f39c12';
                } else {
                    scoreElement.style.color = '#e74c3c';
                }

                log(`‚úÖ Analysis complete: ${adjustedScore}% similarity`);
                log(`‚è±Ô∏è Processing time: ${analysisTime}ms`);
                log(`üìä Comparison: ${currentMasterCall.type} vs recorded call (Engine ${engineId})`);
                log(`üìà Duration match: ${Math.round(durationSimilarity * 100)}%, Energy match: ${Math.round(energySimilarity * 100)}%, Rhythm match: ${Math.round(rhythmSimilarity * 100)}%`);

                if (wasmSimilarity !== null) {
                    log(`üîç WASM engine score: ${Math.round(wasmSimilarity * 100)}%`);
                }

            } catch (error) {
                log(`‚ùå Analysis failed: ${error.message}`, 'error');
                showError(`Analysis failed: ${error.message}`);
            }
        }

        // Run full integration test
        async function runFullTest() {
            log('üöÄ Running full integration test...');

            try {
                // Test 1: WASM loading (already done)
                log('‚úÖ Test 1: WASM module loading - PASSED');

                // Test 2: Audio system
                if (audioContext) {
                    log('‚úÖ Test 2: Audio system initialization - PASSED');
                } else {
                    log('‚ö†Ô∏è Test 2: Audio system not initialized');
                    await testMicrophone();
                }

                // Test 3: Master call loading
                if (!currentMasterCall) {
                    log('üìÅ Test 3: Loading default master call...');
                    document.getElementById('masterCallSelect').value = 'buck_grunt';
                    await loadMasterCall();
                }

                if (currentMasterCall) {
                    log('‚úÖ Test 3: Master call loading - PASSED');
                } else {
                    log('‚ùå Test 3: Master call loading - FAILED');
                }

                // Test 4: Session management (simulated)
                log('üîß Test 4: Testing session management...');
                if (engine && typeof engine.WASMInterface !== 'undefined') {
                    const testInterface = new engine.WASMInterface();
                    const initialized = testInterface.initialize(44100, 1024, 13);
                    if (initialized) {
                        log('‚úÖ Test 4: Session management - PASSED');
                        updateMetric('sessionCount', 1);
                        testInterface.delete();
                        updateMetric('sessionCount', 0);
                    } else {
                        log('‚ùå Test 4: Session management - FAILED');
                    }
                } else {
                    log('‚ö†Ô∏è Test 4: Session management - SKIPPED (interface not available)');
                }

                // Test 5: Memory monitoring
                if (performance.memory) {
                    const memoryMB = Math.round(performance.memory.usedJSHeapSize / 1024 / 1024);
                    updateMetric('memoryUsage', memoryMB);
                    log(`‚úÖ Test 5: Memory monitoring - ${memoryMB}MB used`);
                } else {
                    log('‚ö†Ô∏è Test 5: Memory monitoring not available');
                }

                log('üéØ Full integration test completed');
                log('üìã Summary: Core systems operational, ready for user testing');

            } catch (error) {
                log(`‚ùå Full test failed: ${error.message}`, 'error');
                showError(`Full test failed: ${error.message}`);
            }
        }

        // Utility functions
        function clearOutput() {
            document.getElementById('output').textContent = 'üîç Output cleared...\n';
        }

        function exportLogs() {
            const logs = document.getElementById('output').textContent;
            const blob = new Blob([logs], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `huntmaster-test-logs-${new Date().toISOString().slice(0, 19)}.txt`;
            a.click();
            URL.revokeObjectURL(url);
            log('üìã Logs exported to file');
        }

        // Auto-start initialization when page loads
        window.addEventListener('load', initializeApp);

        // Handle window resize for canvas (with debouncing to prevent stack overflow)
        let resizeTimeout;
        window.addEventListener('resize', () => {
            // Debounce resize events to prevent infinite loops
            clearTimeout(resizeTimeout);
            resizeTimeout = setTimeout(() => {
                try {
                    if (recordedAudio && recordedAudio.getChannelData) {
                        visualizeWaveform(recordedAudio, 'recording');
                    } else if (currentMasterCall && currentMasterCall.buffer && currentMasterCall.buffer.getChannelData) {
                        visualizeWaveform(currentMasterCall.buffer, 'master');
                    }
                } catch (error) {
                    log(`‚ö†Ô∏è Resize visualization failed: ${error.message}`, 'warning');
                }
            }, 250); // 250ms debounce delay
        });

        // Performance monitoring
        setInterval(() => {
            if (performance.memory) {
                const memoryMB = Math.round(performance.memory.usedJSHeapSize / 1024 / 1024);
                updateMetric('memoryUsage', memoryMB);
            }
        }, 5000);

    </script>
</body>

</html>
